name: scrape‑lkq

on:
  schedule:                       # nightly run – change if you prefer
    - cron: '5 3 * * *'           # 03 : 05 UTC
  workflow_dispatch:              # manual trigger button
    inputs:
      ftp_path:
        description: "FTP path to input.csv"
        default: "/webscrapper/input.csv"   # <- your folder from the screenshot
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:                          # repo → Settings → Secrets and variables → Actions
      FTP_HOST:     ${{ secrets.FTP_HOST }}
      FTP_USER:     ${{ secrets.FTP_USER }}
      FTP_PASS:     ${{ secrets.FTP_PASS }}
      LKQ_USERNAME: ${{ secrets.LKQ_USERNAME }}
      LKQ_PASSWORD: ${{ secrets.LKQ_PASSWORD }}

    steps:
    # ────────────── code checkout ──────────────
    - uses: actions/checkout@v4

    # ────────────── Chrome + chromedriver (Option A) ──────────────
    - name: Install Chrome & chromedriver
      run: |
        sudo apt-get update -qq
        # libgconf‑2‑4 removed – not required for recent headless Chrome
        sudo apt-get install -y wget unzip xvfb libxi6
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" \
          | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update -qq
        sudo apt-get install -y google-chrome-stable
        MAJOR=$(google-chrome --version | grep -oP '\d+' | head -1)
        wget -q https://chromedriver.storage.googleapis.com/${MAJOR}.0.0/chromedriver_linux64.zip -O /tmp/cd.zip
        unzip -q /tmp/cd.zip -d $HOME/.local/bin
        chmod +x $HOME/.local/bin/chromedriver
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    # ────────────── Python env ──────────────
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install pip packages
      run: |
        python -m pip install --upgrade pip
        pip install selenium ftplib

    # ────────────── Pull the SKU list ──────────────
    - name: Fetch input.csv from FTP
      run: |
        mkdir -p data
        curl -sS -u "$FTP_USER:$FTP_PASS" \
          "ftp://$FTP_HOST${{ github.event.inputs.ftp_path || '/webscrapper/input.csv' }}" \
          --output data/input.csv

    # ────────────── Run the scraper ──────────────
    - name: Run scraper
      run: |
        xvfb-run -a python scrapeLKQ.py
      env:
        DISPLAY: ':99'

    # ────────────── Keep the results ──────────────
    - uses: actions/upload-artifact@v4
      with:
        name: scrape-output
        path: |
          data/output.csv
          data/unmatchedRims.csv
          images/
