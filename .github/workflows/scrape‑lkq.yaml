name: scrape‑lkq

on:
  schedule:
    - cron: '5 3 * * *'           # 03:05 UTC nightly
  workflow_dispatch:
    inputs:
      ftp_path:
        description: "FTP path to input.csv"
        default: "/webscrapper/input.csv"
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      FTP_HOST:     ${{ secrets.FTP_HOST }}
      FTP_USER:     ${{ secrets.FTP_USER }}
      FTP_PASS:     ${{ secrets.FTP_PASS }}
      LKQ_USERNAME: ${{ secrets.LKQ_USERNAME }}
      LKQ_PASSWORD: ${{ secrets.LKQ_PASSWORD }}

    steps:
    - uses: actions/checkout@v4

    # ───────────── Chrome + chromedriver ─────────────
    - name: Install Chrome & chromedriver
      run: |
        set -eux
        sudo apt-get update -qq
        sudo apt-get install -y wget unzip xvfb libxi6
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" \
          | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update -qq
        sudo apt-get install -y google-chrome-stable

        CHROME_VERSION=$(google-chrome --version | awk '{print $3}')
        CHROME_MAJOR=${CHROME_VERSION%%.*}
        CFT_URL="https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"

        if curl -s --head --fail "$CFT_URL" >/dev/null; then
          wget -q "$CFT_URL" -O /tmp/chromedriver.zip
        else
          DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_MAJOR}" \
                        || curl -s https://chromedriver.storage.googleapis.com/LATEST_RELEASE)
          wget -q "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip" \
            -O /tmp/chromedriver.zip
        fi

        mkdir -p $HOME/.local/bin
        unzip -q /tmp/chromedriver.zip -d /tmp
        mv /tmp/chromedriver-*/chromedriver $HOME/.local/bin/
        chmod +x $HOME/.local/bin/chromedriver
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    # ───────────── Python env ─────────────
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install pip packages
      run: |
        python -m pip install --upgrade pip
        pip install selenium

    # ───────────── Pull the SKU list ─────────────
    - name: Fetch input.csv from FTP
      run: |
        mkdir -p data
        curl -sS -u "$FTP_USER:$FTP_PASS" \
          "ftp://$FTP_HOST${{ github.event.inputs.ftp_path || '/webscrapper/input.csv' }}" \
          --output data/input.csv

    # ───────────── Debug input (prints first lines) ─────────────
    - name: Debug input
      run: cat data/input.csv | head -n 20

    # ───────────── Run the scraper ─────────────
    - name: Run scraper
      run: xvfb-run -a python scrapeLKQ.py
      env:
        DISPLAY: ':99'

    # ───────────── Upload results & login dump ─────────────
    - if: ${{ always() }}
      uses: actions/upload-artifact@v4
      with:
        name: scrape-output
        path: |
          data/output.csv
          data/unmatchedRims.csv
          login_page.html
          login_page.png
          images/
